1) Setup needed: I have used python 3.6.1 and Pycharm to write the code. Certain libraries
   need to be added in order to run the code.


2) Libraries used: import urllib.request      : Urllib.request library

		from bs4 import BeautifulSoup  : BeautifulSoup library

		from collections import OrderedDict : Collections library

		import re   : Regular Expressions library

		import time 
		
 - These are the libraries used in the code and would be required for successful 	       execution.

3) The .py file to be executed for the Task 1-E is wiki.py
   The maximum depth reached in this task was depth-2.

4) The .py file to be executed for the Task 2 is wiki2.py
   The maximum depth reached in this task was depth-6.

5) Execution: Task 1-E; In the wiki.py file to be executed for this task; the main function is main_crawler(). A call to main_crawler() without any parameters would initiate the crawling process.

6) Exection: Task 2; In the wiki2.py file to be executed for this task; the main function is the main_crawler(). A call to main_crawler() without any parameters would initiate the crawling process.

7) Citation: Doubts clarified by talking to a fellow student Varad Choudhari.
