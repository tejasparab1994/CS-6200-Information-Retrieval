Task 1:
	HW4.java is my source code file for the task 1 implementation. The 
assignment asks us to use the SimpleAnalyzer as the analyzer, which has been duely implemented in my program. In order to get top 100 results and sorted in the reverse order I have mentioned "TopScoreDocCollector collector = TopScoreDocCollector.create(100, true)"
the same for the TopScoreDocCollector method create parameters. In order to compute all the 9 queries I have added a queries.txt file in the submission which is read by my code implementation during the execution and the contents are written into a list. Then using a for each loop I compute the scores for each query and write them into a file. I have imported a number of jar files into my project library so that I am able to use the various functions provided by lucene. The Output of this task is placed in the Lucene folder wherein in the file name corresponds to the query ID as mentioned in the assignment. 
 


Task 2: 
	index.py is my source code file for the task 2 implementation of the assignment. The assignment asks us to build a retrieval model of our own, BM25 ranking algorithm. In this task, I have rebuilt the unigram index since rebuilding the unigram index allowed me with the chance to calculate the document length of each document at that point. Since we already open the document, I preferred rather than using the unigram.txt generated through HW 3, I would rebuild the unigram and use it since it made my task easier, providing me with a lot of information needed to compute a BM25 score. On generating a unigram, I have two dictionaies. Basically, A unigram consisting of docid and term frequency along with another dictionary consisting of docid and doclength for all the docs in which the term occurs. 	
	As mentioned in the assignment, Relevance is not to be considered and hence R and r have been set to 0. In order to compute all the 9 queries I have added a queries.txt file in the submission which is read by my code implementation during the execution and the contents are written into a list. Then from the list of queries a single query is passed on to the exec_query function which further divides the query into terms and calculates the bm25 score for that term...the score is updated until all the terms of the query have been completed with the doc scores being updated likewise. While updating the scores of a doc which is stored in a dictionary, I check whether the doc is present in the dictionary, i.e., whether its score has been computed, in case the doc is present in the dictionary the score is just updated rather than creating a new entry of the document.
	The result of all queries is appended into a list, this list is then converted into an ordereddict wherein then I use the sorted function to sort the dictionary in reverse ,i.e. the highest score on top and to write the top 100 results of each query.